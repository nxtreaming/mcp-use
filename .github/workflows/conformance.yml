name: MCP Conformance Tests

on:
  workflow_dispatch:
    inputs:
      python_only:
        description: 'Run only Python conformance tests'
        type: boolean
        default: false
      typescript_only:
        description: 'Run only TypeScript conformance tests'
        type: boolean
        default: false
  push:
    branches:
      - main
      - canary
    paths:
      - 'libraries/python/mcp_use/server/**'
      - 'libraries/python/pyproject.toml'
      - 'libraries/typescript/packages/mcp-use/src/server/**'
      - 'libraries/typescript/packages/mcp-use/package.json'
      - 'libraries/python/tests/integration/servers_for_testing/conformance_server.py'
      - 'libraries/typescript/packages/mcp-use/examples/server/conformance/**'
      - '.github/workflows/conformance.yml'
  pull_request:
    branches:
      - main
      - canary
    paths:
      - 'libraries/python/mcp_use/server/**'
      - 'libraries/python/pyproject.toml'
      - 'libraries/typescript/packages/mcp-use/src/server/**'
      - 'libraries/typescript/packages/mcp-use/package.json'
      - 'libraries/python/tests/integration/servers_for_testing/conformance_server.py'
      - 'libraries/typescript/packages/mcp-use/examples/server/conformance/**'
      - '.github/workflows/conformance.yml'

jobs:
  conformance-python:
    name: Python Server Conformance
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: ${{ github.event_name != 'workflow_dispatch' || !inputs.typescript_only }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Install Python dependencies
        working-directory: libraries/python
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -e ".[dev]"

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Start Python conformance server
        working-directory: libraries/python
        run: |
          source .venv/bin/activate
          python tests/integration/servers_for_testing/conformance_server.py --transport streamable-http --port 8000 &
          sleep 5

      - name: Run conformance tests against Python server
        run: |
          npx @modelcontextprotocol/conformance server --url http://127.0.0.1:8000/mcp 2>&1 | tee python-conformance-results.txt
          # Extract pass/fail summary
          echo "## Python Server Conformance Results" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          grep -E "(SUMMARY|‚úì|‚úó|Total:)" python-conformance-results.txt >> $GITHUB_STEP_SUMMARY || true
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

      - name: Upload Python conformance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: python-conformance-results
          path: |
            python-conformance-results.txt
            results/

  conformance-typescript:
    name: TypeScript Server Conformance
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: ${{ github.event_name != 'workflow_dispatch' || !inputs.python_only }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - name: Install dependencies
        working-directory: libraries/typescript
        run: pnpm install

      - name: Build mcp-use package
        working-directory: libraries/typescript/packages/mcp-use
        run: pnpm build

      - name: Install conformance server dependencies
        working-directory: libraries/typescript/packages/mcp-use/examples/server/conformance
        run: pnpm install

      - name: Start TypeScript conformance server
        working-directory: libraries/typescript/packages/mcp-use/examples/server/conformance
        run: |
          npx tsx src/server.ts &
          sleep 5

      - name: Run conformance tests against TypeScript server
        run: |
          npx @modelcontextprotocol/conformance server --url http://localhost:3000/mcp 2>&1 | tee typescript-conformance-results.txt
          # Extract pass/fail summary
          echo "## TypeScript Server Conformance Results" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          grep -E "(SUMMARY|‚úì|‚úó|Total:)" typescript-conformance-results.txt >> $GITHUB_STEP_SUMMARY || true
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

      - name: Upload TypeScript conformance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: typescript-conformance-results
          path: |
            typescript-conformance-results.txt
            results/

  conformance-summary:
    name: Conformance Summary
    runs-on: ubuntu-latest
    needs: [conformance-python, conformance-typescript]
    if: always() && !cancelled()
    permissions:
      pull-requests: write

    steps:
      - name: Download Python results
        uses: actions/download-artifact@v4
        with:
          name: python-conformance-results
          path: python-results
        continue-on-error: true

      - name: Download TypeScript results
        uses: actions/download-artifact@v4
        with:
          name: typescript-conformance-results
          path: typescript-results
        continue-on-error: true

      - name: Fetch baseline results from main and canary
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const fs = require('fs');
            
            async function fetchBaselineForBranch(branch) {
              try {
                // Find the last successful workflow run for this branch
                const runs = await github.rest.actions.listWorkflowRuns({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: 'conformance.yml',
                  branch: branch,
                  status: 'completed',
                  conclusion: 'success',
                  per_page: 1
                });
                
                if (runs.data.workflow_runs.length === 0) {
                  console.log(`No successful runs found for ${branch}`);
                  return false;
                }
                
                const runId = runs.data.workflow_runs[0].id;
                console.log(`Found run ${runId} for ${branch}`);
                
                // Download artifacts
                const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: runId
                });
                
                const pyArtifact = artifacts.data.artifacts.find(a => a.name === 'python-conformance-results');
                const tsArtifact = artifacts.data.artifacts.find(a => a.name === 'typescript-conformance-results');
                
                // Create baseline directory
                const baseDir = `${branch}-baseline`;
                if (!fs.existsSync(baseDir)) {
                  fs.mkdirSync(baseDir, { recursive: true });
                }
                
                // Download Python artifact
                if (pyArtifact) {
                  const pyDownload = await github.rest.actions.downloadArtifact({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    artifact_id: pyArtifact.id,
                    archive_format: 'zip'
                  });
                  fs.writeFileSync(`${baseDir}/python.zip`, Buffer.from(pyDownload.data));
                  console.log(`Downloaded Python artifact for ${branch}`);
                }
                
                // Download TypeScript artifact
                if (tsArtifact) {
                  const tsDownload = await github.rest.actions.downloadArtifact({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    artifact_id: tsArtifact.id,
                    archive_format: 'zip'
                  });
                  fs.writeFileSync(`${baseDir}/typescript.zip`, Buffer.from(tsDownload.data));
                  console.log(`Downloaded TypeScript artifact for ${branch}`);
                }
                
                return true;
              } catch (error) {
                console.log(`Error fetching baseline for ${branch}:`, error.message);
                return false;
              }
            }
            
            // Fetch baselines for both branches
            await fetchBaselineForBranch('main');
            await fetchBaselineForBranch('canary');

      - name: Extract baseline artifacts
        continue-on-error: true
        run: |
          # Extract main baseline
          if [ -f main-baseline/python.zip ]; then
            unzip -q main-baseline/python.zip -d main-baseline/
            echo "Extracted main Python baseline"
          fi
          if [ -f main-baseline/typescript.zip ]; then
            unzip -q main-baseline/typescript.zip -d main-baseline/
            echo "Extracted main TypeScript baseline"
          fi
          
          # Extract canary baseline
          if [ -f canary-baseline/python.zip ]; then
            unzip -q canary-baseline/python.zip -d canary-baseline/
            echo "Extracted canary Python baseline"
          fi
          if [ -f canary-baseline/typescript.zip ]; then
            unzip -q canary-baseline/typescript.zip -d canary-baseline/
            echo "Extracted canary TypeScript baseline"
          fi

      - name: Parse results to JSON
        id: parse-results
        run: |
          # Function to parse results file into JSON
          parse_results() {
            local file=$1
            local json="{"
            local passed=0
            local failed=0
            local tests=""
            
            if [ -f "$file" ]; then
              while IFS= read -r line; do
                if echo "$line" | grep -q "‚úì"; then
                  test_name=$(echo "$line" | sed 's/.*‚úì[[:space:]]*//' | sed 's/:.*//' | sed 's/[[:space:]]*$//')
                  tests="${tests}\"${test_name}\":true,"
                  ((passed++))
                elif echo "$line" | grep -q "‚úó"; then
                  test_name=$(echo "$line" | sed 's/.*‚úó[[:space:]]*//' | sed 's/:.*//' | sed 's/[[:space:]]*$//')
                  tests="${tests}\"${test_name}\":false,"
                  ((failed++))
                fi
              done < "$file"
            fi
            
            # Remove trailing comma
            tests="${tests%,}"
            
            local total=$((passed + failed))
            local rate="0"
            if [ $total -gt 0 ]; then
              rate=$(echo "scale=1; $passed * 100 / $total" | bc)
            fi
            
            echo "{\"passed\":$passed,\"failed\":$failed,\"rate\":\"$rate\",\"tests\":{$tests}}"
          }
          
          # Parse current result files
          PY_JSON=$(parse_results "python-results/python-conformance-results.txt")
          TS_JSON=$(parse_results "typescript-results/typescript-conformance-results.txt")
          
          # Parse main baseline results
          MAIN_PY_JSON=$(parse_results "main-baseline/python-conformance-results.txt")
          MAIN_TS_JSON=$(parse_results "main-baseline/typescript-conformance-results.txt")
          
          # Parse canary baseline results
          CANARY_PY_JSON=$(parse_results "canary-baseline/python-conformance-results.txt")
          CANARY_TS_JSON=$(parse_results "canary-baseline/typescript-conformance-results.txt")
          
          # Save to files for multiline handling
          echo "$PY_JSON" > py_results.json
          echo "$TS_JSON" > ts_results.json
          echo "$MAIN_PY_JSON" > main_py_results.json
          echo "$MAIN_TS_JSON" > main_ts_results.json
          echo "$CANARY_PY_JSON" > canary_py_results.json
          echo "$CANARY_TS_JSON" > canary_ts_results.json

      - name: Generate summary
        run: |
          echo "# MCP Conformance Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## Python Server" >> $GITHUB_STEP_SUMMARY
          if [ -f python-results/python-conformance-results.txt ]; then
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            grep -E "(‚úì|‚úó)" python-results/python-conformance-results.txt >> $GITHUB_STEP_SUMMARY || echo "No results found" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No results available" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## TypeScript Server" >> $GITHUB_STEP_SUMMARY
          if [ -f typescript-results/typescript-conformance-results.txt ]; then
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            grep -E "(‚úì|‚úó)" typescript-results/typescript-conformance-results.txt >> $GITHUB_STEP_SUMMARY || echo "No results found" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No results available" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Post comment to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const sha = context.sha.substring(0, 7);
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            
            // Helper to safely load JSON
            function loadResults(path) {
              try {
                const content = fs.readFileSync(path, 'utf8');
                return JSON.parse(content);
              } catch (e) {
                return { passed: 0, failed: 0, rate: "0", tests: {} };
              }
            }
            
            // Load all results
            const pyResults = loadResults('py_results.json');
            const tsResults = loadResults('ts_results.json');
            const mainPyResults = loadResults('main_py_results.json');
            const mainTsResults = loadResults('main_ts_results.json');
            const canaryPyResults = loadResults('canary_py_results.json');
            const canaryTsResults = loadResults('canary_ts_results.json');
            
            // Calculate comparison indicators
            function getComparisonIcon(current, baseline) {
              if (!baseline || baseline.passed === 0) return 'üÜï';
              const diff = current.passed - baseline.passed;
              if (diff > 0) return `üü¢ +${diff}`;
              if (diff < 0) return `üî¥ ${diff}`;
              return '‚ö™ +0';
            }
            
            const pyVsMain = getComparisonIcon(pyResults, mainPyResults);
            const pyVsCanary = getComparisonIcon(pyResults, canaryPyResults);
            const tsVsMain = getComparisonIcon(tsResults, mainTsResults);
            const tsVsCanary = getComparisonIcon(tsResults, canaryTsResults);
            
            // Get all unique test names from both servers
            const allTests = [...new Set([
              ...Object.keys(pyResults.tests || {}),
              ...Object.keys(tsResults.tests || {})
            ])].sort();
            
            // Build the table header (use non-breaking hyphens to prevent line breaks)
            const testHeaders = allTests.map(t => t.replace(/-/g, '&#8209;')).join(' | ');
            const headerSeparator = allTests.map(() => ':---:').join(' | ');
            
            // Build Python row with change indicators
            const pyTestCells = allTests.map(test => {
              const current = pyResults.tests[test];
              const baseline = mainPyResults.tests[test];
              
              let icon = '‚ûñ';
              if (current === true) icon = '‚úÖ';
              else if (current === false) icon = '‚ùå';
              
              // Add change indicator if changed from baseline
              if (baseline !== undefined && baseline !== current) {
                if (current === true && baseline === false) return `${icon} +1`;
                if (current === false && baseline === true) return `${icon} -1`;
              }
              
              return icon;
            }).join(' | ');
            
            // Build TypeScript row with change indicators
            const tsTestCells = allTests.map(test => {
              const current = tsResults.tests[test];
              const baseline = mainTsResults.tests[test];
              
              let icon = '‚ûñ';
              if (current === true) icon = '‚úÖ';
              else if (current === false) icon = '‚ùå';
              
              // Add change indicator if changed from baseline
              if (baseline !== undefined && baseline !== current) {
                if (current === true && baseline === false) return `${icon} +1`;
                if (current === false && baseline === true) return `${icon} -1`;
              }
              
              return icon;
            }).join(' | ');
            
            const body = [
              '<h2>',
              '<picture style="display: inline-block; vertical-align: middle; margin-right: 8px;">',
              '  <source media="(prefers-color-scheme: dark)" srcset="https://registry.npmmirror.com/@lobehub/icons-static-png/1.74.0/files/dark/mcp.png">',
              '  <source media="(prefers-color-scheme: light)" srcset="https://registry.npmmirror.com/@lobehub/icons-static-png/1.74.0/files/light/mcp.png">',
              '  <img alt="MCP" src="https://registry.npmmirror.com/@lobehub/icons-static-png/1.74.0/files/light/mcp.png" height="32" width="32" style="display: inline-block; vertical-align: middle;">',
              '</picture>',
              '<span style="vertical-align: middle;">MCP Conformance Test Results</span>',
              '</h2>',
              '',
              `**Commit:** \`${sha}\``,
              '',
              `| Server | Overall | vs Main | vs Canary | ${testHeaders} |`,
              `|--------|:-------:|:-------:|:---------:|${headerSeparator}|`,
              `| Python | ${pyResults.rate}% | ${pyVsMain} | ${pyVsCanary} | ${pyTestCells} |`,
              `| TypeScript | ${tsResults.rate}% | ${tsVsMain} | ${tsVsCanary} | ${tsTestCells} |`,
              '',
              `[View full run details](${runUrl})`
            ].join('\n');
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

